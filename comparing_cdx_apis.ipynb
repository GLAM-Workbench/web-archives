{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing CDX APIs\n",
    "\n",
    "<p class=\"alert alert-info\">New to Jupyter notebooks? Try <a href=\"getting-started/Using_Jupyter_notebooks.ipynb\"><b>Using Jupyter notebooks</b></a> for a quick introduction.</p>\n",
    "\n",
    "This notebook documents differences between the Internet Archive's CDX API and the CDX API available from PyWb systems such as the UK Web Archive and the National Library of Australia.\n",
    "\n",
    "For more details on the data available from the CDX APIs see [Exploring the Internet Archive's CDX API](exploring_cdx_api.ipynb).\n",
    "\n",
    "For examples using CDX APIs to harvest capture data see:\n",
    "\n",
    "* [Find all the archived versions of a web page](find_all_captures.ipynb)\n",
    "* [Harvesting data about a domain using the IA CDX API](harvesting_domain_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "* [Wayback CDX API](https://github.com/internetarchive/wayback/tree/master/wayback-cdx-server)\n",
    "* [PyWb CDXJ Server API](https://pywb.readthedocs.io/en/latest/manual/cdxserver_api.html)\n",
    "* [PyWb indexes](https://pywb.readthedocs.io/en/latest/manual/indexing.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIS = {\n",
    "    \"ia\": {\"url\": \"http://web.archive.org/cdx/search/cdx\", \"type\": \"wb\"},\n",
    "    \"nla\": {\"url\": \"https://web.archive.org.au/awa/cdx\", \"type\": \"pywb\"},\n",
    "    \"bl\": {\"url\": \"https://www.webarchive.org.uk/wayback/archive/cdx\", \"type\": \"pywb\"},\n",
    "    \"nlnz\": {\"url\": \"https://ndhadeliver.natlib.govt.nz/webarchive/cdx\",\"type\": \"pywb\",},\n",
    "    \"ukgwa\": {\"url\": \"https://webarchive.nationalarchives.gov.uk/ukgwa/cdx\",\"type\": \"pywb\",},\n",
    "}\n",
    "\n",
    "\n",
    "def raw_cdx_query(api, url, **kwargs):\n",
    "    params = kwargs\n",
    "    params[\"url\"] = url\n",
    "    params[\"output\"] = \"json\"\n",
    "    response = requests.get(APIS[api][\"url\"], params=params, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between PyWb and IA Wayback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON results format\n",
    "\n",
    "As with Timemaps, requesting `json` formatted results from IA and Pywb CDX servers returns different data structures. IA results are an array of arrays, with the field labels in the first array. Pywb results are formatted as NDJSON (Newline Delineated JSON) â€“ each capture is a JSON object, separated by a line break."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Archive (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['urlkey',\n",
       "  'timestamp',\n",
       "  'original',\n",
       "  'mimetype',\n",
       "  'statuscode',\n",
       "  'digest',\n",
       "  'length'],\n",
       " ['au,com,discontents)/',\n",
       "  '19981206012233',\n",
       "  'http://www.discontents.com.au:80/',\n",
       "  'text/html',\n",
       "  '200',\n",
       "  'FQJ6JMPIZ7WEKYPQ4SGPVHF57GCV6B36',\n",
       "  '1610']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_cdx_query(\"ia\", \"discontents.com.au\", limit=1, format=\"json\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urlkey': 'au,com,discontents)/',\n",
       " 'timestamp': '19981206012233',\n",
       " 'url': 'http://www.discontents.com.au/',\n",
       " 'mime': 'text/html',\n",
       " 'status': '200',\n",
       " 'digest': 'FQJ6JMPIZ7WEKYPQ4SGPVHF57GCV6B36',\n",
       " 'offset': '59442416',\n",
       " 'filename': 'NLA-EXTRACTION-1996-2004-ARCS-PART-00309-000001.arc.gz',\n",
       " 'length': '1610',\n",
       " 'source': 'awa',\n",
       " 'source-coll': 'awa'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(raw_cdx_query(\"nla\", \"discontents.com.au\", limit=1, format=\"json\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Field labels\n",
    "\n",
    "As with Timemaps, some of the field labels are different between the two systems:\n",
    "\n",
    "|IA|PyWb|\n",
    "|---|---|\n",
    "|`original`|`url`|\n",
    "|`statuscode`|`status`|\n",
    "|`mimetype`|`mime`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Archive (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urlkey',\n",
       " 'timestamp',\n",
       " 'original',\n",
       " 'mimetype',\n",
       " 'statuscode',\n",
       " 'digest',\n",
       " 'length']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_cdx_query(\"ia\", \"discontents.com.au\", limit=1, format=\"json\").json()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urlkey',\n",
       " 'timestamp',\n",
       " 'url',\n",
       " 'mime',\n",
       " 'status',\n",
       " 'digest',\n",
       " 'offset',\n",
       " 'filename',\n",
       " 'length',\n",
       " 'source',\n",
       " 'source-coll']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    json.loads(\n",
    "        raw_cdx_query(\"nla\", \"discontents.com.au\", limit=1, format=\"json\").text\n",
    "    ).keys()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLNZ (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urlkey',\n",
       " 'timestamp',\n",
       " 'url',\n",
       " 'mime',\n",
       " 'status',\n",
       " 'digest',\n",
       " 'redirect',\n",
       " 'robotflags',\n",
       " 'length',\n",
       " 'offset',\n",
       " 'filename',\n",
       " 'load_url',\n",
       " 'source',\n",
       " 'source-coll']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    json.loads(\n",
    "        raw_cdx_query(\"nlnz\", \"http://digitalnz.org\", limit=1, format=\"json\").text\n",
    "    ).keys()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UKWA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urlkey',\n",
       " 'timestamp',\n",
       " 'url',\n",
       " 'mime',\n",
       " 'status',\n",
       " 'digest',\n",
       " 'redirect',\n",
       " 'robotflags',\n",
       " 'length',\n",
       " 'offset',\n",
       " 'filename',\n",
       " 'load_url',\n",
       " 'source',\n",
       " 'source-coll',\n",
       " 'access']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    json.loads(\n",
    "        raw_cdx_query(\n",
    "            \"bl\", \"anjackson.net\", filter=\"status:200\", limit=1, format=\"json\"\n",
    "        ).text\n",
    "    ).keys()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UKGWA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urlkey',\n",
       " 'timestamp',\n",
       " 'url',\n",
       " 'mime',\n",
       " 'status',\n",
       " 'digest',\n",
       " 'redirect',\n",
       " 'robotflags',\n",
       " 'length',\n",
       " 'offset',\n",
       " 'filename',\n",
       " 'source',\n",
       " 'source-coll',\n",
       " 'access']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    json.loads(\n",
    "        raw_cdx_query(\n",
    "            \"ukgwa\", \"https://www.nationalarchives.gov.uk/\", filter=\"status:200\", limit=1, format=\"json\"\n",
    "        ).text\n",
    "    ).keys()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Match types\n",
    "\n",
    "From the documentation it seems that you should be able to supply a `matchType` or use url wildcards on both systems. But there seem to be some inconsistences. In summary:\n",
    "\n",
    "* UKWA needs **both** the url wildcard and the `matchType` parameter to work correctly\n",
    "* domain queries do not work with NLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)\n",
    "\n",
    "Prefix queries work as expected, Domain queries do not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for an exact url\n",
    "exact = len(\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"http://discontents.com.au\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using url wildcard works as expected\n",
    "prefix_url = len(\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"http://discontents.com.au*\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49773"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using matchType=prefix works as expected\n",
    "prefix_match = len(\n",
    "    raw_cdx_query(\n",
    "        \"nla\",\n",
    "        \"http://discontents.com.au\",\n",
    "        filter=\"status:200\",\n",
    "        format=\"json\",\n",
    "        matchType=\"prefix\",\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain query using url wildcard causes exception\n",
    "# This test passes if there is a HTPPError exception\n",
    "with pytest.raises(requests.exceptions.HTTPError):\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"*.discontents.com.au\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain query using matchType parameter causes exception\n",
    "# This test passes if there is a HTPPError exception\n",
    "with pytest.raises(requests.exceptions.HTTPError):\n",
    "    raw_cdx_query(\n",
    "        \"nla\",\n",
    "        \"discontents.com.au\",\n",
    "        filter=\"status:200\",\n",
    "        format=\"json\",\n",
    "        matchType=\"domain\",\n",
    "    ).text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the results\n",
    "assert isinstance(exact, int) is True\n",
    "assert isinstance(prefix_url, int) is True\n",
    "assert isinstance(prefix_match, int) is True\n",
    "assert prefix_url > exact\n",
    "assert prefix_url == prefix_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UKWA (PyWb)\n",
    "\n",
    "Domain and prefix queries work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for an exact url\n",
    "exact = len(\n",
    "    raw_cdx_query(\n",
    "        \"bl\", \"anjackson.net\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24072"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using url wildcard works as expected\n",
    "prefix_url = len(\n",
    "    raw_cdx_query(\n",
    "        \"bl\", \"http://anjackson.net/*\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using matchType prefix works as expected\n",
    "prefix_match = len(\n",
    "    raw_cdx_query(\n",
    "        \"bl\",\n",
    "        \"http://anjackson.net\",\n",
    "        filter=\"status:200\",\n",
    "        format=\"json\",\n",
    "        matchType=\"prefix\",\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37117"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Domain query using url wildcard works as expected\n",
    "domain_url = len(\n",
    "    raw_cdx_query(\n",
    "        \"bl\", \"*.anjackson.net\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "domain_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37117"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Domain query using matchType parameter works as expected\n",
    "domain_match = len(\n",
    "    raw_cdx_query(\n",
    "        \"bl\", \"anjackson.net\", filter=\"status:200\", format=\"json\", matchType=\"domain\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "domain_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the results\n",
    "assert isinstance(exact, int) is True\n",
    "assert isinstance(prefix_url, int) is True\n",
    "assert isinstance(prefix_match, int) is True\n",
    "assert isinstance(domain_url, int) is True\n",
    "assert isinstance(domain_match, int) is True\n",
    "assert prefix_url > exact\n",
    "assert prefix_url == prefix_match\n",
    "assert domain_url > exact\n",
    "assert domain_url > prefix_url\n",
    "assert domain_url == domain_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLNZ (pywb)\n",
    "\n",
    "Domain and prefix queries work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for an exact url\n",
    "exact = len(\n",
    "    raw_cdx_query(\n",
    "        \"nlnz\", \"http://digitalnz.org/\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16718"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using url wildcard works as expected\n",
    "prefix_url = len(\n",
    "    raw_cdx_query(\n",
    "        \"nlnz\", \"http://digitalnz.org/*\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16718"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using matchType prefix works as expected\n",
    "prefix_match = len(\n",
    "    raw_cdx_query(\n",
    "        \"nlnz\",\n",
    "        \"http://digitalnz.org/\",\n",
    "        filter=\"status:200\",\n",
    "        format=\"json\",\n",
    "        matchType=\"prefix\",\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72178"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Domain query using url wildcard works as expected\n",
    "domain_url = len(\n",
    "    raw_cdx_query(\n",
    "        \"nlnz\", \"*.digitalnz.org\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "domain_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72178"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Domain query using matchType parameter works as expected\n",
    "domain_match = len(\n",
    "    raw_cdx_query(\n",
    "        \"nlnz\", \"digitalnz.org\", filter=\"status:200\", format=\"json\", matchType=\"domain\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "domain_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the results\n",
    "assert isinstance(exact, int) is True\n",
    "assert isinstance(prefix_url, int) is True\n",
    "assert isinstance(prefix_match, int) is True\n",
    "assert isinstance(domain_url, int) is True\n",
    "assert isinstance(domain_match, int) is True\n",
    "assert prefix_url > exact\n",
    "assert prefix_url == prefix_match\n",
    "assert domain_url > exact\n",
    "assert domain_url > prefix_url\n",
    "assert domain_url == domain_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UKGWA (pywb)\n",
    "\n",
    "Domain and prefix queries work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for an exact url\n",
    "exact = len(\n",
    "    raw_cdx_query(\n",
    "        \"ukgwa\", \"http://www.mod.uk/\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using url wildcard works as expected\n",
    "prefix_url = len(\n",
    "    raw_cdx_query(\n",
    "        \"ukgwa\", \"http://www.mod.uk/*\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prefix query using matchType prefix works as expected\n",
    "prefix_match = len(\n",
    "    raw_cdx_query(\n",
    "        \"ukgwa\",\n",
    "        \"http://www.mod.uk/\",\n",
    "        filter=\"status:200\",\n",
    "        format=\"json\",\n",
    "        matchType=\"prefix\",\n",
    "    ).text.splitlines()\n",
    ")\n",
    "prefix_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33436"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Domain query using url wildcard works as expected\n",
    "domain_url = len(\n",
    "    raw_cdx_query(\n",
    "        \"ukgwa\", \"*.mod.uk\", filter=\"status:200\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "domain_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33436"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Domain query using matchType parameter works as expected\n",
    "domain_match = len(\n",
    "    raw_cdx_query(\n",
    "        \"ukgwa\", \"mod.uk\", filter=\"status:200\", format=\"json\", matchType=\"domain\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "domain_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the results\n",
    "assert isinstance(exact, int) is True\n",
    "assert isinstance(prefix_url, int) is True\n",
    "assert isinstance(prefix_match, int) is True\n",
    "assert isinstance(domain_url, int) is True\n",
    "assert isinstance(domain_match, int) is True\n",
    "assert prefix_url > exact\n",
    "assert prefix_url == prefix_match\n",
    "assert domain_url > exact\n",
    "assert domain_url > prefix_url\n",
    "assert domain_url == domain_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Collapse\n",
    "\n",
    "PyWb doesn't support the `collapse` parameter. So if you want to remove duplicates, you'll need to use something like Pandas `.drop_duplicates()` after the results have arrived. However, `collapse` only works on adjacent index entries, so if only having unique values is important, you'll probably want to run `.drop_duplicates()` on it anyway,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Archive (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without collapse -- total number of results (subtract one for the header row)\n",
    "complete = len(raw_cdx_query(\"ia\", \"discontents.com.au\", format=\"json\").json()) - 1\n",
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With collapse -- should only be one result as we're collapsing on urlkey and searching for an exact url\n",
    "collapsed = (\n",
    "    len(\n",
    "        raw_cdx_query(\n",
    "            \"ia\", \"discontents.com.au\", format=\"json\", collapse=\"urlkey\"\n",
    "        ).json()\n",
    "    )\n",
    "    - 1\n",
    ")\n",
    "collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert complete > collapsed\n",
    "assert collapsed == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UKWA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without collapse\n",
    "complete = len(raw_cdx_query(\"bl\", \"anjackson.net\", format=\"json\").text.splitlines())\n",
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With collapse\n",
    "collapsed = len(\n",
    "    raw_cdx_query(\n",
    "        \"bl\", \"anjackson.net\", collapse=\"urlkey\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "# Collapse has done nothing\n",
    "assert complete == collapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De-duplicate results using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    json.loads(line)\n",
    "    for line in raw_cdx_query(\n",
    "        \"bl\", \"anjackson.net\", fields=\"urlkey\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    "]\n",
    "df = pd.DataFrame(data).drop_duplicates(subset=[\"urlkey\"])\n",
    "deduped = df.shape[0]\n",
    "deduped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert deduped == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Sort and Closest\n",
    "\n",
    "IA doesn't support `sort` or the `closest` parameter. To implement something similar, I suppose you could use `from` and `to` to set a window around a date, and then process the results to calculate time deltas and sort by 'closeness'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Limiting fields\n",
    "\n",
    "The parameter used for limiting the fields returned from a query used to be different, but this has changed in recent PyWb releases. The IA server expects `fl`, while PyWb expects either `fields` or `fl`. So for cross-compaibility, use `fl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urlkey': 'au,com,discontents)/'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_fl = json.loads(\n",
    "    raw_cdx_query(\"nla\", \"discontents.com.au\", limit=1, fl=\"urlkey\", format=\"json\").text\n",
    ")\n",
    "use_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urlkey': 'au,com,discontents)/'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_fields = json.loads(\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"discontents.com.au\", limit=1, fields=\"urlkey\", format=\"json\"\n",
    "    ).text\n",
    ")\n",
    "use_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert use_fl == use_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IA (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['urlkey'], ['au,com,discontents)/']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_fl_ia = json.loads(\n",
    "    raw_cdx_query(\"ia\", \"discontents.com.au\", limit=1, fl=\"urlkey\", format=\"json\").text\n",
    ")\n",
    "use_fl_ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text expected results\n",
    "assert use_fl_ia[1][0] == \"au,com,discontents)/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Comparison operators in filters\n",
    "\n",
    "This seems to create the most potential for confusion. In PyWb, the `filter` parameter uses a number of different operators to indicate the type of match required. IA only uses `!`. There's no way of indicating a query should be treated as a regular expression in IA, therefore, all queries are treated as regular expressions.\n",
    "\n",
    "| Operator | Example | Result |\n",
    "|---|---|---|\n",
    "| no operator | `filter=mime:html` | `mime` field contains 'html'|\n",
    "| `=` | `filter==mime:text/html` | `mime` field matches 'text/html' exactly |\n",
    "| `~` | `filter=~status:30\\d{1}` | `status` field matches any 3 digit code starting with 30|\n",
    "| `!` | `filter=!mime:html` | `mime` field doesn't contain 'html' |\n",
    "| `!=` | `filter=!=mime:text/html` | `mime` field doesn't match 'text/html' exactly |\n",
    "| `!~` | `filter=!~status:30\\d{1}` | `status` field doesn't match any 3 digit codes starting with 30 |\n",
    "\n",
    "IA filter queries look for an exact match (which could be a regular expression) by default. This can be negated by using the `!` operator.\n",
    "\n",
    "| Operator | Example | Result |\n",
    "|---|---|---|\n",
    "| no operator | `filter=mimetype:text/html` | `mimetype` field matches 'text/html'|\n",
    "| `!` | `filter=!mimetype:text/html` | `mimetype` field doesn't match 'text/html' exactly |\n",
    "\n",
    "In IA you need to use a regular expression to find a field containing a particular value. So these two expressions should result in the same matching behaviour:\n",
    "\n",
    "| PyWb | IA |\n",
    "|---|---|\n",
    "|`filter=mime:powerpoint`|`filter=mimetype:.*powerpoint.*`|\n",
    "\n",
    "For interoperability, it seems easiest to always use regular expressions, inserting the `~` operator for PyWb systems. So: \n",
    "\n",
    "| PyWb | IA |\n",
    "|---|---|\n",
    "|`filter=~mime:.*powerpoint.*`|`filter=mimetype:.*powerpoint.*`|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Archive (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filters are treated as exact matches by default\n",
    "ia_exact = len(\n",
    "    raw_cdx_query(\n",
    "        \"ia\",\n",
    "        \"defence.gov.au/*\",\n",
    "        filter=\"mimetype:powerpoint\",\n",
    "        format=\"json\",\n",
    "        collapse=\"urlkey\",\n",
    "    ).json()\n",
    ")\n",
    "ia_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using regex finds results including 'powerpoint' in mimetype\n",
    "ia_regex = (\n",
    "    len(\n",
    "        raw_cdx_query(\n",
    "            \"ia\",\n",
    "            \"defence.gov.au/*\",\n",
    "            filter=\"mimetype:.*powerpoint.*\",\n",
    "            format=\"json\",\n",
    "            collapse=\"urlkey\",\n",
    "        ).json()\n",
    "    )\n",
    "    - 1\n",
    ")\n",
    "ia_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert ia_regex > ia_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='web.archive.org.au', port=443): Read timed out. (read timeout=60)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    783\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 785\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/packages/six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:451\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:340\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout_value\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='web.archive.org.au', port=443): Read timed out. (read timeout=60)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Filter values are treated as regex by default\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nla_exact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mraw_cdx_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnla\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefence.gov.au/*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmime:powerpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m nla_exact\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mraw_cdx_query\u001b[0;34m(api, url, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m url\n\u001b[1;32m     13\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPIS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='web.archive.org.au', port=443): Read timed out. (read timeout=60)"
     ]
    }
   ],
   "source": [
    "# Filter values are treated as regex by default\n",
    "nla_exact = len(\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"defence.gov.au/*\", filter=\"mime:powerpoint\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "nla_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly use regex\n",
    "nla_regex = len(\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"defence.gov.au/*\", filter=\"~mime:.*powerpoint.*\", format=\"json\"\n",
    "    ).text.splitlines()\n",
    ")\n",
    "nla_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert nla_exact == nla_regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Pagination\n",
    "\n",
    "Both IA and PyWb *can* support pagination or results, however, it's not available by default in PyWb. It's only available if repositories are [using ZipNum indexes](https://pywb.readthedocs.io/en/latest/manual/cdxserver_api.html#pagination-api). The UKGWA supports pagination but none of the UKWA, National Library of Australia, or National Library of New Zealand CDX APIs support it. This means that queries to these systems will return **all** matching results in one hit (unless there is a system defined limit). This is something to bear in mind as large requests might be slow and prone to breakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Archive (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ia_pages = raw_cdx_query(\n",
    "    \"ia\", \"discontents.com.au\", showNumPages=\"true\", format=\"json\"\n",
    ").text\n",
    "ia_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urlkey': 'au,com,discontents)/',\n",
       " 'timestamp': '19981206012233',\n",
       " 'url': 'http://www.discontents.com.au/',\n",
       " 'mime': 'text/html',\n",
       " 'status': '200',\n",
       " 'digest': 'FQJ6JMPIZ7WEKYPQ4SGPVHF57GCV6B36',\n",
       " 'offset': '59442416',\n",
       " 'filename': 'NLA-EXTRACTION-1996-2004-ARCS-PART-00309-000001.arc.gz',\n",
       " 'length': '1610',\n",
       " 'source': 'awa',\n",
       " 'source-coll': 'awa'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLA CDX server just ignores the showNumPages parameter and performs the query as normal\n",
    "nla_pages = json.loads(\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"discontents.com.au\", showNumPages=\"true\", format=\"json\"\n",
    "    ).text.splitlines()[0]\n",
    ")\n",
    "nla_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLNZ (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urlkey': 'org,digitalnz)/',\n",
       " 'timestamp': '20090129060149',\n",
       " 'url': 'http://www.digitalnz.org/',\n",
       " 'mime': 'text/html',\n",
       " 'status': '200',\n",
       " 'digest': '3CTAFWGHTJMGYCHECAFS4HKHPXIZOMWO',\n",
       " 'redirect': '-',\n",
       " 'robotflags': '-',\n",
       " 'length': '0',\n",
       " 'offset': '6208429',\n",
       " 'filename': 'V1-FL994870.arc',\n",
       " 'load_url': 'http://10.4.1.66:80/nlnzwebarchive_PROD/ap/20090129060149id_/http://www.digitalnz.org/',\n",
       " 'source': 'webarchive',\n",
       " 'source-coll': 'webarchive'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLNZ CDX server just ignores the showNumPages parameter and performs the query as normal\n",
    "nlnz_pages = json.loads(\n",
    "    raw_cdx_query(\n",
    "        \"nlnz\", \"digitalnz.org\", showNumPages=\"true\", format=\"json\"\n",
    "    ).text.splitlines()[0]\n",
    ")\n",
    "nlnz_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UKGWA (Pywb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pages': 1, 'pageSize': 10, 'blocks': 0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UKGWA seerver supports pagination\n",
    "ukgwa_pages = json.loads(\n",
    "    raw_cdx_query(\n",
    "        \"ukgwa\", \"www.mod.org.uk\", showNumPages=\"true\", format=\"json\"\n",
    "    ).text.splitlines()[0]\n",
    ")\n",
    "ukgwa_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert ia_pages.strip().isnumeric()\n",
    "assert isinstance(nla_pages, dict)\n",
    "assert isinstance(nlnz_pages, dict)\n",
    "assert type(ukgwa_pages['pages']) == int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Fuzzy matching\n",
    "\n",
    "If your query to a PyWb CDX API returns no matches, the system will use regular expressions to broaden your search and return a set of 'fuzzy' matches. These results will include an `is_fuzzy` field set to a value of `1`. This is not supported in IA.\n",
    "\n",
    "While fuzzy matching is useful for discovery, it might not be what you want if you're assembling a specific dataset. In this case you'd need to filter the results to remove the `is_fuzzy` matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Archive (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This should return no results\n",
    "ia_not_fuzzy = raw_cdx_query(\n",
    "    \"ia\", \"discontents.com.au\", limit=1, filter=\"statuscode:666\", format=\"json\"\n",
    ").json()\n",
    "\n",
    "# Test expected result\n",
    "assert ia_not_fuzzy == []\n",
    "ia_not_fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urlkey': 'au,com,discontents)/',\n",
       " 'timestamp': '19981206012233',\n",
       " 'url': 'http://www.discontents.com.au/',\n",
       " 'mime': 'text/html',\n",
       " 'status': '200',\n",
       " 'digest': 'FQJ6JMPIZ7WEKYPQ4SGPVHF57GCV6B36',\n",
       " 'offset': '59442416',\n",
       " 'filename': 'NLA-EXTRACTION-1996-2004-ARCS-PART-00309-000001.arc.gz',\n",
       " 'length': '1610',\n",
       " 'source': 'awa',\n",
       " 'source-coll': 'awa',\n",
       " 'is_fuzzy': '1'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This would return no results except for fuzzy matching\n",
    "# Note the status value in the result and the 'is_fuzzy' field\n",
    "nla_fuzzy = json.loads(\n",
    "    raw_cdx_query(\n",
    "        \"nla\", \"discontents.com.au\", limit=1, filter=\"status:666\", format=\"json\"\n",
    "    ).text\n",
    ")\n",
    "\n",
    "# Test expected result\n",
    "assert nla_fuzzy[\"is_fuzzy\"] == \"1\"\n",
    "nla_fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising queries\n",
    "\n",
    "It would be possible to wrap some code around queries that simulated `collapse` and `closest` across the two systems, but for the moment I'll just focus on some basic normalisation of query parameters and results. The functions below:\n",
    "\n",
    "* Normalise field names in queries and results\n",
    "* Convert results into a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_filter(api, f):\n",
    "    \"\"\"\n",
    "    Standardise field names in filters.\n",
    "    \"\"\"\n",
    "    sys_type = APIS[api][\"type\"]\n",
    "    if sys_type == \"pywb\":\n",
    "        f = f.replace(\"mimetype:\", \"mime:\")\n",
    "        f = f.replace(\"statuscode:\", \"status:\")\n",
    "        f = f.replace(\"original:\", \"url:\")\n",
    "        f = re.sub(r\"^(!{0,1})(\\w)\", r\"\\1~\\2\", f)\n",
    "    elif sys_type == \"wb\":\n",
    "        f = f.replace(\"mime:\", \"mimetype:\")\n",
    "        f = f.replace(\"status:\", \"statuscode:\")\n",
    "        f = f.replace(\"url:\", \"original:\")\n",
    "    return f\n",
    "\n",
    "\n",
    "def normalise_filters(api, filters):\n",
    "    \"\"\"\n",
    "    Standardise field names in filters.\n",
    "    \"\"\"\n",
    "    if isinstance(filters, list):\n",
    "        normalised = []\n",
    "        for f in filters:\n",
    "            normalised.append(normalise_filter(api, f))\n",
    "    else:\n",
    "        normalised = normalise_filter(api, filters)\n",
    "    return normalised\n",
    "\n",
    "\n",
    "def convert_lists_to_dicts(results):\n",
    "    \"\"\"\n",
    "    Converts IA style timemap (a JSON array of arrays) to a list of dictionaries.\n",
    "    Renames keys to standardise IA with other Timemaps.\n",
    "    \"\"\"\n",
    "    if results:\n",
    "        keys = results[0]\n",
    "        results_as_dicts = [dict(zip(keys, v)) for v in results[1:]]\n",
    "    else:\n",
    "        results_as_dicts = results\n",
    "    for d in results_as_dicts:\n",
    "        d[\"status\"] = d.pop(\"statuscode\")\n",
    "        d[\"mime\"] = d.pop(\"mimetype\")\n",
    "        d[\"url\"] = d.pop(\"original\")\n",
    "    return results_as_dicts\n",
    "\n",
    "\n",
    "def query_cdx(api, url, **kwargs):\n",
    "    \"\"\"\n",
    "    Make a request to a CDX API, normalising filters and responses across Wayback & PyWb systems.\n",
    "    \"\"\"\n",
    "    params = kwargs\n",
    "    if \"filter\" in params:\n",
    "        params[\"filter\"] = normalise_filters(api, params[\"filter\"])\n",
    "    params[\"url\"] = url\n",
    "    params[\"output\"] = \"json\"\n",
    "    response = requests.get(APIS[api][\"url\"], params=params)\n",
    "    # print(response.url)\n",
    "    response.raise_for_status()\n",
    "    response_type = response.headers[\"content-type\"].split(\";\")[0]\n",
    "    # print(response_type)\n",
    "    if response_type == \"text/x-ndjson\":\n",
    "        data = [json.loads(line) for line in response.text.splitlines()]\n",
    "    elif response_type == \"application/json\":\n",
    "        data = convert_lists_to_dicts(response.json())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some examples â€“ note that the parameters and their values are unchanged, you can just switch repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internet Archive (Wayback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'urlkey': 'au,gov,defence)/28sqn/ad097.pdf',\n",
       "  'timestamp': '20140304175138',\n",
       "  'digest': 'AQBSAVSJJYOYKKLW7GM36PDCYDREFQXA',\n",
       "  'length': '141731',\n",
       "  'status': '200',\n",
       "  'mime': 'application/pdf',\n",
       "  'url': 'http://www.defence.gov.au/28sqn/AD097.pdf'}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ia_normalised1 = query_cdx(\n",
    "    \"ia\", \"defence.gov.au/*\", filter=[\"mime:.*pdf\", \"status:200\"], limit=1\n",
    ")\n",
    "ia_normalised1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'urlkey': 'au,gov,defence)/28sqn/ad097.pdf',\n",
       "  'timestamp': '20140304175138',\n",
       "  'digest': 'AQBSAVSJJYOYKKLW7GM36PDCYDREFQXA',\n",
       "  'length': '141731',\n",
       "  'status': '200',\n",
       "  'mime': 'application/pdf',\n",
       "  'url': 'http://www.defence.gov.au/28sqn/AD097.pdf'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ia_normalised2 = query_cdx(\n",
    "    \"ia\", \"defence.gov.au/*\", filter=[\"mimetype:.*pdf\", \"status:200\"], limit=1\n",
    ")\n",
    "ia_normalised2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert ia_normalised1 == ia_normalised2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLA (PyWb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'urlkey': 'au,gov,defence)/',\n",
       "  'timestamp': '19981202111842',\n",
       "  'url': 'http://www.defence.gov.au/',\n",
       "  'mime': 'text/html',\n",
       "  'status': '200',\n",
       "  'digest': 'ERQQ3XVKGL4VFGI4KXIPE24QI7YMW4Z6',\n",
       "  'offset': '8871025',\n",
       "  'filename': 'NLA-EXTRACTION-1996-2004-ARCS-PART-00307-000001.arc.gz',\n",
       "  'length': '4038',\n",
       "  'source': 'awa',\n",
       "  'source-coll': 'awa',\n",
       "  'is_fuzzy': '1'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nla_norm = query_cdx(\n",
    "    \"nla\",\n",
    "    \"defence.gov.au\",\n",
    "    filter=[\"mimetype:.*pdf\", \"status:200\"],\n",
    "    matchType=\"prefix\",\n",
    "    limit=1,\n",
    ")\n",
    "nla_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test expected results\n",
    "assert \"mime\" in nla_norm[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Created by [Tim Sherratt](https://timsherratt.org) for the [GLAM Workbench](https://glam-workbench.github.io). Support me by becoming a [GitHub sponsor](https://github.com/sponsors/wragge)!\n",
    "\n",
    "Work on this notebook was supported by the [IIPC Discretionary Funding Programme 2019-2020](http://netpreserve.org/projects/).\n",
    "\n",
    "The Web Archives section of the GLAM Workbench is sponsored by the [British Library](https://www.bl.uk/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
